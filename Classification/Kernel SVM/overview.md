# Kernel SVM

만약 데이터가 선형으로 분리되기 어려운 상황이라면...?

SVM 알고리즘은 데이터가 선형으로 분리 가능한 상태에서 사용 가능

그런데 선형으로 결정되지 않는 데이터의 카테고리 구분의 경우라면 어떻게 해야 할까?

데이터 차원을 고차원으로 바꾸어 선형으로 바꾸는 방법을 사용함

그러면 데이터의 차원을 어떻게 증가시켜야 원래 비선형으로 분리되는 데이터를 고차원에서 선형으로 분리되도록 만들 수 있을까?

고차원으로 이동시키면 원래 선형으로 분리되지 않던 것도 선형으로 분리되도록 데이터의 함수를 변경할 수 있음!

mapping function이라는 것이 동작하여, 보다 고차원으로 변경하는데
고차원으로 변경하고 나서 그 하이퍼플레인으로 데이터를 선형적으로 분리하게 됨 (고차원 형태에서의 선형)
그리고 그것을 다시 원래의 데이터 차원으로 사영을 진행!

그런데 고차원으로 변경하는 부분이 연산이 많이 필요한 부분이라, 최선의 선택은 될 수 없다고 함

그래서 이것을 우회하는 방법으로 커널 트릭을 사용하게 되면 고차원으로 변경할 필요가 없음...!

# Kernel Trick
Kernel 
벡터 둘과 연관된 함수
Gaussian RBF Kernel

3차원의 가우시안 분포를 띄게 만드는 함수

2차원으로 펼쳐진 데이터를 kernel함수의 landmark를 이용하여...

gaussian rbf kernel쪽의 함수에서는 landmark 원을 그리고
그 원 내부에 있는 값에 0보다 큰 값을 지정
그 외부에는 아무런 값도 지정하지 않음..

시그마가 커지면 그 원의 지름이 커지고, 시그마가 작아지면 원의 지름이 작아짐

결정 경계라는 것을 만들어, 데이터를 나누는 기준을 설정할 수 있음!!

커널 함수 둘을 선형 조합하여 복잡한 데이터의 분포로 커널 함수를 이용하여 쉽게 구분, 분리할 수 있음!

다만 실제로는 계수값이 들어가기 때문에 위의 과정보다 조금 더 복잡한 계산 과정이 추가

커널함수의 유형
Gaussian RBF Kernel
비선형적으로 결정 경계 원을 그려 데이터를 구분

Sigmoid Kernel
특정 기준이 있어 해당 기준을 경계로 확률이 크게 증가, 감소

polynomial kernel
고차원의 다항식으로 구성된 kernel 함수

그 외에도 다양한 커널들이 있음
대체로 위의 3가지 유형의 커널만 사용하여도 대부분의 데이터 구분 활용에 문제 없이 활용됨

# 비선형 SVR
비선형 SVR

support vector regression을 하려면 support vector를 무엇으로 골라야 ??

비선형 SVR을 진행하기 위해서는 어떻게 하는가?

커널 함수를 이용하여 커널 함수를 하이퍼플레인(고차원의 선형)으로 나누고 나서, 데이터 평면의 차원과 겹치는 부분을 그대로 선으로 이어 붙이게 되면
비선형의 형태로 데이터를 구분하게 됨

하이퍼 플레인의 support vector들은??
하이퍼 플레인의 위, 아래를 결정하게 되는 support vector라서, 현재의 데이터 차원에서는 선형으로 보이지 않는 부분이 있음
